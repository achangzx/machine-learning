在进行异常检测的过程中，往往需要选定参数epsilon
  有关epsilon的概念
    对数据集（测试集）的每个特征计算其均值和方差，并且绘制出直方图（往往都是服从高斯分布），那么每一个（新的样本，就是交叉验证集的数据）样本输入都会量化得到一个概率pi，那么p=p1*p2*p3...
    通过比较如果p<epsilon,则我们说我们预测这个样本是异常的
  有关epsilon选取的原理
    通过对有有标签的（监督学习）的交叉验证集对训练结果进行验证，F得分越高，说明epsilon选择的越好，F的计算公式如下：
  
  
  
  
  
  
  
  
  1、通过对epsiolon进行迭代，从一个非常小的值迭代到一个稍微大一点的值，每次迭代都对交叉验证集进行测试，分别计算tp,fp,fn
    tp（真阳性）:预测是异常的，实际上的y对应的标签也是异常的
    fp（假阳性）:预测是异常的，实际上的y对应的标签是正常的
    fn（假阴性）:预测是正常的，实际上的y对应的标签是异常的
  2、然后分别计算prec（预测异常的里面确实是异常的比例）
                rec（确实是异常的被真正检测出来的比例）
  3、计算参数得分F=(2*prec*rec)/(prec+rec)  这个得分越高说明我们的epsionlon选取的越好
  4、涉及除法问题，为了防止分母出现零（随着epsiolon不断变大，会使得我们的预测可能都是错的，导致tp，fn都是0，），所以需要加上if语句，如果一旦出现了上述情况直接跳过即可
  5、最后我们需要对F不断更新，因为F越大越好，if F>F_BEST: F_BEST=F,epsilon_best=epsilon
